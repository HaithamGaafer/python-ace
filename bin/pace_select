#!/usr/bin/env python
import argparse
import logging
from collections import Counter

import numpy as np
import psutil
import pandas as pd
import os

from ase.io import write

from pyace import BBasisConfiguration, ACEBBasisSet, aseatoms_to_atomicenvironment
from pyace.activelearning import compute_B_projections, compute_A_active_inverse, compute_active_set_by_batches, \
    read_extrapolation_data, compute_number_of_functions, load_active_inverse_set, \
    count_number_total_atoms_per_species_type_aseatom, compute_active_set
from pyace.preparedata import sizeof_fmt

LOG_FMT = '%(asctime)s %(levelname).1s - %(message)s'
logging.basicConfig(level=logging.INFO, format=LOG_FMT, datefmt="%Y/%m/%d %H:%M:%S")
log = logging.getLogger()

parser = argparse.ArgumentParser(prog="pace_select",
                                 description="Utility to select structures for training se based on D-optimality criterion")

parser.add_argument("dataset", nargs='+',
                    help="Dataset file name(s), ex.: filename.pckl.gzip [extrapolative_structures.dat]",
                    type=str)

parser.add_argument("-p", "--potential_file", help="B-basis file name (.yaml)", type=str,
                    required=True)

parser.add_argument("-a", "--active-set-inv", help="Active Set Inverted (ASI) filename",
                    default=None, type=str, dest="active_set_inv_fname")

parser.add_argument("-e", "--elements", type=str, help='List of elements, used in LAMMPS, i.e. "Ni Nb O"')

parser.add_argument("-m", "--max-structures", type=int,
                    dest="max_structures",
                    help="Maximum number of structures to select (default -1 = all)",
                    default=-1)

parser.add_argument("-o", "--output", dest="selected_structures_filename", type=str,
                    help="Selected structures filename: selected.pkl.gz or structures/POSCAR (default: selected.pkl.gz)",
                    default="selected.pkl.gz"
                    )

parser.add_argument("-b", "--batch_size", help="Batch size (number of structures) considered simultaneously."
                                               "If not provided - all dataset at once is considered",
                    default="auto", type=str)
parser.add_argument("-g", "--gamma_tolerance", help="Gamma tolerance",
                    default=1.01, type=float)

parser.add_argument("-i", "--maxvol_iters", help="Number of maximum iteration in MaxVol algorithm",
                    default=300, type=int)

parser.add_argument("-r", "--maxvol_refinement", help="Number of refinements (epochs)",
                    default=2, type=int)

parser.add_argument("-mem", "--memory-limit", help="Memory limit (i.e. 1GB, 500MB or 'auto')", default="auto", type=str)

parser.add_argument("-V", help="suppress verbosity of numerical procedures",
                    dest="not_verbose", default=False, action="store_true")

args_parse = parser.parse_args()
potential_file = args_parse.potential_file

dataset_filename = args_parse.dataset

batch_size = args_parse.batch_size
gamma_tolerance = args_parse.gamma_tolerance
maxvol_iters = args_parse.maxvol_iters
maxvol_refinement = args_parse.maxvol_refinement

max_structures = args_parse.max_structures
selected_structures_filename = args_parse.selected_structures_filename

mem_lim = args_parse.memory_limit
if mem_lim == "auto":
    # determine 80% of available memory
    mem_lim = int(0.8 * psutil.virtual_memory().available)
else:
    mem_lim = mem_lim.replace("GB", "*2**30").replace("MB", "*2**20")
    mem_lim = eval(mem_lim)

verbose = not args_parse.not_verbose

active_set_inv_fname = args_parse.active_set_inv_fname
if active_set_inv_fname is None:
    active_set_inv_fname = potential_file.replace(".yaml", ".asi")
if not os.path.isfile(active_set_inv_fname):
    active_set_inv_fname = None

if isinstance(dataset_filename, list):
    df_list = []
    for i, dsfn in enumerate(dataset_filename):
        if not os.path.isfile(dsfn):
            raise RuntimeError("File {} not found".format(dsfn))

        log.info("Loading dataset #{}/{} from {}".format(i + 1, len(dataset_filename), dsfn))
        if dsfn.endswith(".pckl.gzip") or dsfn.endswith(".pkl.gz"):
            df = pd.read_pickle(dsfn, compression="gzip")
            log.info("Number of structures: {}".format(len(df)))
            df_list.append(df)
        elif dsfn.endswith(".dat") or dsfn.endswith(".dump"):
            elements = args_parse.elements
            if elements is None:
                raise ValueError('`elements` are missing. Provide it as in LAMMPS with --elements "A B C"')
            species_to_element_dict = {i + 1: e for i, e in enumerate(elements.split())}
            # LAMMPS dat format
            structures = read_extrapolation_data(dsfn, species_to_element_dict=species_to_element_dict)
            df = pd.DataFrame({"ase_atoms": structures})
            df_list.append(df)
        else:
            raise ValueError(f"Unsupported file type: {dsfn}")
    df = pd.concat(df_list, axis=0)
    df.reset_index(drop=True, inplace=True)
else:
    raise ValueError("Unrecognized --dataset (-d) argument: {}".format(dataset_filename))
log.info(f"{len(df['ase_atoms'])} structures in candidate list")
log.info(f"Loading B-basis configuration from {potential_file}")
bconf = BBasisConfiguration(potential_file)
bbasis = ACEBBasisSet(bconf)
nfuncs = compute_number_of_functions(bbasis)
elements_to_index_map = bbasis.elements_to_index_map
elements_name = bbasis.elements_name

if active_set_inv_fname:
    log.info(f"Loading Active Set Inverted  from {active_set_inv_fname}")
    asi = load_active_inverse_set(active_set_inv_fname)
    active_set = compute_A_active_inverse(asi)
else:
    log.info(f"No Active Set Inverted provided")
    active_set = None

n_projections = nfuncs

ase_atoms_list = df["ase_atoms"]
structure_ind_list = df.index
total_number_of_atoms_per_species_type = count_number_total_atoms_per_species_type_aseatom(ase_atoms_list,
                                                                                           elements_to_index_map)
number_of_projection_entries = 0
required_active_set_memory = 0
for st in total_number_of_atoms_per_species_type.keys():
    log.info("\tElement: {}, # atoms: {}, # B-func: {}, # projections: {}".format(elements_name[st],
                                                                                  total_number_of_atoms_per_species_type[
                                                                                      st],
                                                                                  nfuncs[st], n_projections[st]
                                                                                  ))
    number_of_projection_entries += total_number_of_atoms_per_species_type[st] * n_projections[st]
    required_active_set_memory += n_projections[st] ** 2

required_projections_memory = number_of_projection_entries * 8  # float64
required_active_set_memory *= 8  # in bytes, float64
log.info("Required memory to store complete dataset projections: {}".format(sizeof_fmt(required_projections_memory)))
log.info("Required memory to store active set: {}".format(sizeof_fmt(required_active_set_memory)))

if batch_size == "auto":
    log.info("Automatic batch_size determination")
    log.info("Memory limit: {}".format(sizeof_fmt(mem_lim)))
    if 2 * required_projections_memory + required_active_set_memory < mem_lim:
        batch_size = None
    else:
        nsplits = int(np.ceil(2 * required_projections_memory // (mem_lim - required_active_set_memory)))
        batch_size = int(np.round(len(ase_atoms_list) / nsplits))
elif batch_size in ["None", "none"]:
    batch_size = None
else:
    batch_size = int(batch_size)

if batch_size is None:
    # single shot MaxVol
    log.info("Single-shot mode")
    log.info("Compute B-projections")
    b_proj, structure_ind_dict = compute_B_projections(bconf, ase_atoms_list,
                                                       return_structure_ind_dict=True, verbose=True)
    log.info("Selecting structures")
    res_no_batch = compute_active_set(b_proj, structure_ind_dict,
                                      tol=gamma_tolerance, max_iters=maxvol_iters,
                                      extra_A0_projections_dict=active_set, verbose=True)
    selected_structures_inds_dict = res_no_batch[1]
else:
    # batching
    log.info("Batch mode")
    n_batches = len(ase_atoms_list) // batch_size
    log.info("Number of batches: {}".format(n_batches))
    log.info("Selecting structures in batch mode")
    res_batch = compute_active_set_by_batches(bconf, ase_atoms_list,
                                              n_batches=n_batches,
                                              gamma_tolerance=gamma_tolerance,
                                              maxvol_iters=maxvol_iters,
                                              n_refinement_iter=maxvol_refinement,
                                              save_interim_active_set=True,
                                              extra_A_active_set_dict=active_set,
                                              verbose=True)
    selected_structures_inds_dict = res_batch[2]

cnt = Counter()
for mu, sel_structs in selected_structures_inds_dict.items():
    cnt.update(sel_structs)
if -1 in cnt:
    cnt.pop(-1)  # remove structures from active set
log.info(f"Overall {len(cnt)} structures selected")

selected_structures_inds = ([int(i) for i, _ in cnt.most_common() if i != -1])
if max_structures > 0:
    log.info(f"Selection top {max_structures} structures")
    if max_structures <= len(selected_structures_inds):
        selected_structures_inds = selected_structures_inds[:max_structures]

df_selected = df.iloc[selected_structures_inds]

# save selected structures
if "POSCAR" in selected_structures_filename:
    log.info(f"Saving selected structures to {selected_structures_filename.replace('POSCAR', '*.POSCAR')}")
    os.makedirs(os.path.dirname(selected_structures_filename), exist_ok=True)
    for i, at in enumerate(df_selected["ase_atoms"]):
        fname = selected_structures_filename.replace("POSCAR", "{}.POSCAR".format(i))
        write(fname, at, format="vasp", sort=True)
else:
    log.info(f"Saving selected structures to {selected_structures_filename} as pickled dataframe")
    df_selected.to_pickle(selected_structures_filename)
log.info("Done")
